{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\jakub\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin our model testing by splitting data into train and test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train_data_after_EDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7608    1\n",
       "7609    1\n",
       "7610    1\n",
       "7611    1\n",
       "7612    1\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df['cleaned_tokens']\n",
    "y=df['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test these models and vectorizers:\n",
    "- Models:\n",
    "    - Random Forest\n",
    "    - SVM\n",
    "    - Logistic Regression\n",
    "    - Multinomial NB\n",
    "- Vectorizers:\n",
    "    - Count Vectorizer\n",
    "    - CBow\n",
    "    - Tfidf Vectorizer\n",
    "    - Skipgram Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GensimVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_type='cbow', size=100, window=5, min_count=1, workers=4):\n",
    "        self.model_type = model_type\n",
    "        self.size = size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        model_type = 0 if self.model_type == 'cbow' else 1\n",
    "        self.model = Word2Vec(X, vector_size=self.size, window=self.window, min_count=self.min_count, workers=self.workers, sg=model_type)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.model.wv[word] for word in sentence if word in self.model.wv] or [np.zeros(self.size)], axis=0) for sentence in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prepare\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    #'Multinomial NB': MultinomialNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizers\n",
    "vectorizers = {\n",
    "    'TFidf': TfidfVectorizer(),\n",
    "    'Count': CountVectorizer(),\n",
    "    'Skipgram': GensimVectorizer(model_type='skipgram'),\n",
    "    'CBow': GensimVectorizer(model_type='cbow')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        predictions = pipeline.predict(X_test)\n",
    "        \n",
    "        report = classification_report(y_test, predictions, output_dict=True)\n",
    "        results.append({\n",
    "            'Vectorizer': vec_name,\n",
    "            'Model': model_name,\n",
    "            'Report': report\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Vectorizer                Model  \\\n",
      "0       TFidf        Random Forest   \n",
      "1       TFidf                  SVM   \n",
      "2       TFidf  Logistic Regression   \n",
      "3       Count        Random Forest   \n",
      "4       Count                  SVM   \n",
      "5       Count  Logistic Regression   \n",
      "6    Skipgram        Random Forest   \n",
      "7    Skipgram                  SVM   \n",
      "8    Skipgram  Logistic Regression   \n",
      "9        CBow        Random Forest   \n",
      "10       CBow                  SVM   \n",
      "11       CBow  Logistic Regression   \n",
      "\n",
      "                                               Report  \n",
      "0   {'0': {'precision': 0.782608695652174, 'recall...  \n",
      "1   {'0': {'precision': 0.7783300198807157, 'recal...  \n",
      "2   {'0': {'precision': 0.7866666666666666, 'recal...  \n",
      "3   {'0': {'precision': 0.7790224032586558, 'recal...  \n",
      "4   {'0': {'precision': 0.7810650887573964, 'recal...  \n",
      "5   {'0': {'precision': 0.7927736450584485, 'recal...  \n",
      "6   {'0': {'precision': 0.6929057337220602, 'recal...  \n",
      "7   {'0': {'precision': 0.5923076923076923, 'recal...  \n",
      "8   {'0': {'precision': 0.5894736842105263, 'recal...  \n",
      "9   {'0': {'precision': 0.6882352941176471, 'recal...  \n",
      "10  {'0': {'precision': 0.6229641693811075, 'recal...  \n",
      "11  {'0': {'precision': 0.6484230055658627, 'recal...  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Model Testing Results\", dataframe=results_df)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
